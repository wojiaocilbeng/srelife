网络概述

- （1）常用概念

  - 处理时延：将对数据包分组进行检测、决定将其转发到哪条链路上所消耗的时间
  - 排队时延：在决定转发的链路后，需要等待正在排队向该链路传输的其他分组的时间；如果不需要等待，则排队时延为0
  - 传输时延、存储转发时延：将分组推送到链路上的时间；分组长度/链路速率
  - 传播时延： 两个路由之间的数据传输的耗时；传播距离/传播速度
  -  流量强度：分组到达缓存队列的平均速率/传播速度；设计系统时流量强度不应该超过1，因为一旦流量强度超过1，缓存队列中就会一直存在等待分组，从而导致排队时延趋近于无穷
  - 丢包：当缓存队列被占满时就会将之后的分组丢弃
  - 瞬间吞吐量：主机接受该文件的速率
  - 协议栈：各层所有协议的集合
  - 各层数的名称：应用层=报文，运输层=报文段，网络层=数据报/数据段，链路层=数据帧，物理层=比特
  - MAC 地址：物理地址、链路层地址；与IP一同以二进制方式表示；IP地址长度为4字节（32位），MAC 地址长度为6字节（48位）；用于唯一标识网络适配器（网卡）；局域网内有效地址，当MAC 地址经过网关后就会发生改变，因为局域网发生了变化
  - MTU：最大传输单元，两台主机之间的所以网络报文段中MTU的最小值；通常用于避免数据分片
  - 网络协议三要素：语义、语法、顺序
  - DHCP 运行机制（要背）：Client使用 0.0.0.0 向 255.255.255.255 发送UDP请求（原先是BOOTP请求，UDP是更高级的封装)，当 DHCP 服务器捕获到请求之后回复ACK表示成功接收请求。
  - PXE 协议解析过程（要背）：
  - 广播风暴：ARP广播的时候会将一个端口收到的数据包转发到其他所有端口，当交换机互联出现环路以后，就会形成广播风暴，导致循环发送数据包，硬件资源耗尽
    - 只有交换机会使用ARP协议（地址解析协议）
    - ARP 协议：根据 IP 地址找到物理地址（MAC 地址）的一个 TCP/IP 协议
    - 集线器是直接将数据广播到所以端口，交换机是查表找到需要数据的端口发送过去
    - 生成树协议：开机以后直接广播一条数据，这样就能发现环路并将其标记，使其数据线不传输信号
  - Hub（集线器）只有一个广播域和冲突域；Switch（交换机）有一个广播域和多个冲突域，可以划分多个 VLAN，形成每个端口在划分 VLAN 的情况下都是一个冲突域；路由器有多个广播域和多个冲突域

- （2）广播信道和点对点信道

  - 广播信道
    - 主要有两种控制方法进行协调，一个为使用信道复用技术，一个是使用 CSMA/CD 协议
    - CSMA/CD 协议
      - 多点接入：这时总线型网络，多台主机一多点的方式连接到总线（bus）上
      - 载波监听：
      - 碰撞检测
  - 点对点信道
    - 不会方式碰撞，使用 PPP 协议进行控制
      - PPP 协议：数据链路层协议

- （3）NAT（重点）

  - NAT（网络地址转换） 用于在本地网络中使用私有地址，在连接互联网是转而使用全局IP地址的技术，是为了解决 IPv4 地址短缺而开发的技术

  - NAT 的三种方式
    - SNAT（静态转换）：是指数据包从网卡发送出去的时候，把数据包中的源地址部分替换为指定的IP地址，这样对方就认为数据包的来源是被替换的那个IP的主机
    - DNAT（动态转换）：是指数据包从网卡发送出去的时候，修改数据包中的目的IP，表现为如果你想访问A，可是因为网关NAT做了DNAT，把所有访问A的数据包更换为B的IP
    - MASQUEEADE︰是用发送数据的网卡上的 IP 替换 源IP，因此对于那些IP不固定的场合，比如拨号网络或者通过 DHCP 分配的情况下就可以使用该方式
  - NAT 三种模式的区别：路由是按照目的IP来选择的，因此DNAT是在pre-routing链上进行的，而SNAT是数据包发送出去的时候才进行的，因此是post-routing链上进行的
  - 转发网关与NAT网关的区别：两者主要的区别在于IP地址是否改变。不改变IP地址的网关，只转发数据包的，我们称为转发网关；改变P地址的网关，我们称为NAT网关 



应用层

- （1）FTP 协议（重点）

  - FTP 基于 TCP 的，FTP 使用20端口作为控制端口，21端口作为数据端口；控制信息是带外的

  - 主动模式（Port）和被动模式（Passive）
- （2）DNS 协议（重点）：作为域名和IP地址互相映射的一个分布式数据库

  - 作用：正向解析--域名查找IP地址；反向解析--IP地址查找域名

  - DNS 协议使用53端口，基于 UDP 协议
  - DNS 服务器分类：根 DNS 服务器；TLD 顶级域 DNS 服务器；权威 DNS 服务器；公共 DNS 服务器；本地 DNS 服务器
  - DNS 记录：用来指定该域名由哪个DNS服务器来进行解析，由Name,Value,Type,TTL构成的四元组
    - A 记录：主机名 ---- 主机IP
    - NS 记录：主机域 ---- 权威 DNS 地址
    - CNAME 记录：别名 ---- 主机名
    - MX 记录：邮件服务地址 ---- Web 服务地址
    - NS 记录和 SOA 记录是任何一个 DNS 区域都不可或缺的两条记录，NS 记录也叫名称服务器记录，用于说明这个区域有哪些DNS服务器负责解析，SOA 记录说明负责解析的DNS服务器中哪一个是主服务器。因此。任何一个 DNS 区域都不可能缺少这两条记录。
    - NS 记录说明了在这个区域里有多少个服务器来承担解折析的任务，SOA 叫起始授权机构记录，SOA 记录说明了在众多 NS 记录里那一台才是主要的服务器
    - SRV 记录
    - PTR 记录：指针记录，是A 记录的逆向记录，作用是把IP地址解析为域名
  - 传统 DNS  存在的问题
    - 域名缓存：运营商缓存和本地缓存
    - 域名转发：某些运营商偷懒将DNS转发到其他运营商，其他运营商返回的是自己网络内部的IP，导致网速慢
    - 出口 NAT：IP地址不同导致运营商误判
    - 域名更新：权威 DNS 更新后其他 DNS 更新漫长
    - 解析延迟：DNS的查询需要递归遍历多个DNS服务器才能获得最终的解析结果
- HTTP DNS（重点）

  - 不走传统的DNS解析，而是自己搭建基于 HTTP 协议的 DNS 服务器集群，分布在多个地点和多个远营商。当客户端需要DNS解析的时候，直接通过 HTTP 协议进行请求这个服务器集群，得到就近的地址，使用 HTTP DNS的，往往是手机应用，需要在手机端嵌入支持 HTTP DNS 的客户端 SDK。
  - CDN（内容分发网络） ：核心理念就是将内容缓存在终端用户附近
    - 原理：就是采用更多的缓存服务器，分布放在用户访问相对集中的地区或网络中。当用户访问网站时，利用全局负载技术，将用户的访问指向距离最近的缓存服务器上，由缓存服务器响应用户请求
    - CDN 的两种工作方式
      - 边缘计算模式：定时从源数据那里同步存储的数据，然后在边缘进行计算得到结果
      - 路径优化模式：源站点生成数据分发，根据地理位置寻找最近分发点
- HTTP、HTTPS、QUIC 协议

  - HTTP 与邮箱协议

    - SMTP 客户端运行在25端口上
    - HTTP 是拉协议，也是非持久连接，可以用QPS（每秒请求数）衡量
    - SMTP 是推协议，是持久连接
  - HTTP 状态码（重点）
  
    - 1xx 信息
      - 100 Continue:表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应
    - 2xx 成功
      - 200 OK
      - 204 No Content：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用
      - 206 Partial Content：表示客户端进行了范围请求，响应报文包含由Content-Range 指定范围的实体内容。
    - 3xx 重定向
      - 301 Moved Permanently ：永久性重定向
      - 302 Found ：临时性重定向
      - 303 See Оther：和302有着相同的功能，但是303明确要求客户端应该采用 GET 方法获取资源。注：虽然HTTP协议规定301、302状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在301、302和303状态下的重定向把POST方法改成GET方法。
      - 304 Not Modified：如果请求报文首部包含一些条件，例如:Fi-Match，If-Modified-Since,，If-None-Match, If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回304状态码
      - 307 Temporary Redirect：临时重定向，与302的含义类似，但是307要求浏览器不会把重定向请求的 POST 方法改成 GET 方法
    - 4xx 客户段错误
      - 400 Bad Request：请求报文中存在语法错误
      - 401 Unauthorized：该状态码表示发送的请求需要有认证信息(BASIC认证、DIGEST认证)。如果之前已进行过一次请求，则表示用户认证失败
      - 403 Forbidden：请求被拒绝
      - 404 Not Found
    - 5xx 服务端错误
      - 500 Internal Server Error ：服务器正在执行请求时发生错误。
      - 503 Service Unavailable：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求
  - HTTP 1.1和2.0的区别（重点）

    - HTTP 的报文大概分为三大部分。第一部分为请求行（方法 + URL + 版本），第二部分是请求的首部（键值对），第三部分才是请求的正文实体

    - HTTP 协议基于 TCP 协议，因此使用面向连接的方式发送请求，通过 Stream 二进制流的方式传给对方

    - 到了 TCP 层，会将二进制流变成一个的报文段发送给服务器

    - HTTP 1.1

      - HTTP 1.1 在应用层中以纯文本的形式进行通信。因为每次通信都带有完整的 HTTP 头，而且不考虑 pipeline（流水线） 模式的话，每次的过程总是像上面描述的那样一去一回。因此会影响性能，在实时性、并发性上都存在问题

    - HTTP 2.0

      - 为了解决 HTTP 1.1 的这些问题，HTTP 2.0 对 HTTP  的头部进行了一定的压缩，在key value 的两端建立一个索引表，将相同的头只发送到索引表中的索引
      - HTTP 2.0 协议将一个 TCP 的连接中，切分成多个流，每个流都有自己的 ID；流可以是客户端发送到服务端，也可以是服务端发送到客户端；流只是一个虚拟的通道；流是有优先级的
      - HTTP 2.0 还将传输信息分为更小的消息和帧
      - HTTP 2.0 成功解决了部分 HTTP 1.1 的队首阻塞问题。同时，也不需要通过 HTTP1.1 的 pipeline 机制用多条 TCP 连接来实现并行请求与响应；**减少了 TCP 连接数对服务器性能的影响**，同时将页面的多个数据 css、js、jpg等合并，通过一个数据链接进行传输，**能够加快页面组件的传输速度**
      - HTTP 2.0 虽然大大增加了并发性，但因为是基于 TCP 协议的，TCP 协议在处理包时是有严格顺序的。当数据包出现问题时，需要将数据包完成重传之后才能继续进行
        - 重传：在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据，也就是我们常说的超时重传
  - HTTP 1.1 的缺陷（重点）
    - 高延迟：主要问题是由于队首阻塞，导致带宽无法被充分利用
    - 无状态：HTTP 的头部信息会很大
    - 明文传输：不安全
    - 不支持服务器推送消息
  - HTTP 2.0 的缺陷
    - TCP  的 TLS 连接建立耗时
    - TCP  队头阻塞的问题还没完全解决
  - QUIC 协议（重点）
  
    - Google 的QUIC 协议是基于 UDP 的低时延的互联网传输层协议
    - 自定义连接机制
      - 一条 TCP 连接是由四元组标识的，分别是源IP、源端口、目的IP、目的端口；一旦一个元素发生变化时，就需要断开重连。在移动互联网情况下，当手机信号不稳定或者在 WIFI 和移动网络切换时，都会导致重连，从而进行再次的三次握手，导致一定的时延。这在TCP是没有办法的
      - 但是基于UDP，就可以在QUIC自己的逻辑里面维护连接的机制，不再以四元组标识，而是以一个64位的随机数作为 ID 来标识，而且UDP是无连接的，即逻辑连接。所以当 IP 或者端口变化的时候，只要 ID 不变，就不需要重新建立连接。
    - 自定义重传机制（要理解）
    - 无阻塞的多路复用：无阻塞的多路复用:同 HTTP 2.0 一样，同一条QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。但是，QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖。例如，B 给 用户 发送一个 UDP 包失败了，B 就要给 用户 重新发送一个 UDP 包，但 B 后面的 C 不需要等待 B ，可以直接发送给 用户
    - 自定义流量控制：QUIC 的流量控制是通过 window_update ，来告诉对端它可以接受的字节数
      - window_update：一般大于等于0，当小于0时就说明接收端要丢包了。例如，A 能处理 5 个包，B 能处理 3 个包，当窗口为 -2 时，发送段需要减少 2 个包给接收端，即发送 3 个包；当窗口为 0 时，禁止发送段传输包；当窗口为 2 时，发送端需要发送 2 个包给接收端
      - 虽然窗口为 -2 时和窗口为 3 时都是发送 3 个包，但是负数就意味着会丢包，所以通常都选 3
  - SSL 的四次握手过程（要背）
  - HTTPS 的缺陷（重点）
  
    - HTTPS 协议握手阶段比较耗时、耗电
    - HTTPS 连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响。
    - SSL 证书需要钱，功能越强费用越高
    - SSL 证书通常需要绑定 IP，不能在同一 IP 上绑定多个域名，IPv4 资源不可能支撑这个消耗
    - HTTPS 协议的加密范围也比较有限
      - 访问网站时出现红三角证明证书是美国发的，不安全
  - HTTPS 性能优化（重点）
    - TCP 性能优化：每个 TCP 连接都有一个称为拥塞窗口的速度极限，因为 TCP 是运行在设备上的，而每个设备的吞吐量不一致，所以窗口会随时间增长；这种机制称为慢启动；所有的 TCP  的连接启动速度很慢；当握手协议大于窗口的大小，发送端发送握手协议就需要拆分为两块，从而降低性能；启动速度限制被称为初始拥塞窗口；在 Linux 上，可以在连接空闲时禁用慢启动
    - 使用长连接
    - 尽可能使用 HTTP 2.0 版本
    - CDN 
    - 减少秘钥交换：密钥交换的 CPU 消耗很大程度上取决于服务器选择的私钥算法、私钥长度和密钥交换算法，所有要减少秘钥交换从而降低 CPU 消耗
    - 证书：一次完整的 TLS 握手期间，服务器会把它的证书链发送给客户端验证。证书链的长度和正确性对握手的性能有很大影响
      - 证书链：证书是由证书证明的，这样证书套着证书称为证书链
    - 吊销检查：虽然证书吊销状态在不断变化，并且用户代理对证书吊销的行为差异很大，但是作为服务器，要做的就是尽可能快地传递吊销信息
  - HTTPS 11次握手流程图（要背）（重点）
  - HTTP 与 Restful（重点）
    - HTTPS 采用混合的加密机制：使用非对称密钥加密用于传输对称密钥来保证传输过程的安全性
    - 所有的安全方法也都是幂等的：POST 之所以不是幂等的，是因为 POST 等同于创建，每次创建都会生成一个新的 ID
    - HTTP 协议本身是—种面向资源的应用层协议，使用上存在着两种不同的方式：一种是RESTful，它把 HTTP 当成应用层协议，比较忠实地遵守了 HTTP 协议的各种规定；一种是SOA ，SOA 将HTTP 协议作为传输层协议，然后在 HTTP 上建立自己的协议。用得最多的是 POST
    -  在使用 XMLHTTPRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data，但并不是所有浏览器会这么做，例如火狐就不会；GET 方法 Header 和 Data 会一起发送
    - HTTPS 并非是应用层的一种新协议，它只是在HTTP通信接口部分用 SSL (Secure Socket Layer)和 TLs  (TransportLayer Security)协议代替而已



传输层

- （1）概述与 UDP

  - 运输层协议是为运行在不同主机上的**进程**提供逻辑通信，而网络层协议是为**主机**提供逻辑通信
    - 路由器可算作主机，交换机不是主机
  - TCP 与七层 OSI/RM 对应关系：
    - 应用层：应用层，表示层，会话层
    - 传输层：传输层
    - 网络层：网络层
    - 网络接入层：数据链路层，物理层
  - TCP 协议的信息分组叫做数据段，而 UDP 协议的信息分组叫做数据报
  - 进程可能有多个套接字（Socket），每个套接字都有一个唯一的标识符，其格式取决于是 TCP 套接字还是 UDP 套接字
  - UDP 的套接字是 2 元组，TCP 的是 4 元组
  - UDP 的套接字使用（目的地址、目的端口）描述（重点要背）
  - TCP 的套接字使用（源地址、源端口、目的地址、目的端口）描述（重点要背）
  - UDP 发送报文是并没有双方握手，因此 UDP 是面向无连接的，适合广播
  - RIP 的选路表就是使用的 UDP，UDP 的首部只有 4 个字段，每个字段 2 字节
    - 1 bit = 0.125字节；8 bit = 1 字节

- （2）TCP 连接与状态

  - TCP 连接是一种面向连接的、面向单播的协议。一个 TCP 连接通常分为启动、数据传输和退出三个阶段

    - SYN：同步
    - 通常情况下，客户端为了建立连接会频繁的发送 SYN 报文段，第一个 SYN 报文段发出后第二个仅隔 3 秒就会发送第二个，然后间隔 6 秒发送第三个，依次类推，这种方式叫做指数回退，因为超时时间越来越长
    - 通常选择一个较小的值，在 Linux 中 net.ipv4.tcp_syn_retries 表示一次主动申请打开尝试发送 SYN 报文段的最大次数，net.ipv4.tcp_synack_retires 表示响应对方的一个主动打开请求发送

  - 连接时序图为三次握手和四次挥手（重点要背）

    - 三次握手

      - 客户端发送一个SYN段，并指明客户端的初始序列号，即ISN(c)

      - 服务端发送自己的SYN段作为应答，同样指明自己的ISN(s)。为了确认客户端的SYN，将ISN(c)+1作为ACK数值。这样，每发送一个SYN，序列号就会加1， 如果有丢失的情况，则会重传

      - 为了确认服务器端的SYN，客户端将ISN(s)+1作为返回的ACK数值

    - 四次挥手
  
      - 客户端发送一个FIN段，并包含一个希望接收者看到的自己当前的序列号K. 同时还包含一个ACK表示确认对方最近一次发过来的数据。
  
      - 服务端将K值加1作为ACK序号值，表明收到了上一个包。这时上层的应用程序会被告知另一端发起了关闭操作，通常这将引起应用程序发起自己的关闭操作
  
      - 服务端发起自己的FIN段，ACK=K+1, Seq=L 
  
      - 客户端确认。ACK=L+1
  
    - 为什么建立连接时三次握手，而关闭连接却是四次握手
  
      这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方ACK和FIN一般都会分开发送
  
  - 大量 TIME_WAIT 造成的影响：在高并发短连接的 TCP 服务器上，当服务器处理完请求后立刻主动正常关闭连接
  
    - 这个场景下会出现大量 Socket 处于 TIME _WAIT 状态一直被占用无法被释放。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上
  
    - 创建大量的 TCP 连接然后 close，出现大量的连接出现 TIME_WAIT 的状态

    - 主动正常关闭 TCP 连接，都会出现 TIME_WAIT

    - 关注这个高并发短连接的两个原因：

      - 高并发可以让服务器在短时间范围内同时占用大量端口，而端口有个0~65535的范围，并不是很多，刨除系统和其他服务要用的，剩下的就更少了。
      - 在这个场景中，短连接表示"业务处理+传输数据的时间 远远小于 TIME_WAIT超时的时间"的连接
  
    - 如何尽量处理 TIME_WAIT 过多（要背）
  
      - 编辑内核文件/etc/sysctl.conf
  
      - 简单来说，就是打开系统的TIMEWAIT重用和快速回收。
  
    - TIME_WAIT 状态的产生是主动关闭连接产生的，CLOSE_WAIT 的关闭是被动关闭连接产生的
  
    - 大量的 TIME_WAIT (常见于爬虫服务器或者 Web 服务器）可能会导致程序无法接收更多的连接，解决大量 TIME_WAIT 快速回收的方法有三种:
  
      - 主动调用shutdown()函数
      - 使用池化技术
        - 提前准备一些资源，在需要时可以重复使用这些预先准备的资源。
      - 设置内核参数
  
    - 通常大量的 CLOSE_WAIT 的产生是服务器程序出现 Bug 导致的，通过调整内核参数无法得到改善
  
      - 例如，服务器a 使用简单的 HttpClient 库去请求服务器b 的数据，如果请求成功，在抓取完成后，服务器a会发出关闭连接的请求，这就是自动关闭连接；如果服务器b 上不存在相关数据，服务器b 就会发出关闭连接的请求，这时服务器a 只能被动关闭连接，之后如果忘记释放 HttpClient 连接，就会造成 CLOSE_WAIT 的状态
  
    - 半关闭模式
  
      - TCP 提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力，这就是TCP的半关闭
      - 当一方关闭发送通道后，仍可接受另一方发送过来的数据，这样的情况叫“半关闭”。
  
      - TCP 支持半关闭模式；一般用于通知等数据传输
      - Half-Open（半开放模式）模式存在无法感知对方是否宕机的问题，因此 TCP 设计了Keepalive 选项用来防止 Half-Open 由于对方宕机导致无法关闭
  
      - 半关闭状态出现在 四次挥手阶段，主动关闭链接方 和 被动关闭链接方 都会进入这个状态
      - 三次握手由 2个 FIN 和 2个 ACK 组成，发送出 FIN 还没 收到对端的 ACK 的状态就是半关闭状态，所以主动/被动都可能进入半打开状态
      - **TIME_WAIT 不是半关闭状态，此时已经走完四次挥手了； CLOSE_WAIT也不是半关闭状态，因为此时作为被动关闭方，其已经收到对端的FIN，只是应用程序没有主动关闭socket(读socket发现读到文件结束符，然后调用close函数)**

    - 对于同时打开或者同时关闭的情况
  
      - 同时打开，服务器始终是被动的打开者，因此可以区分服务器与客户端，而且连接被区分为两个 TCP 连接。一个同时打开的情况需要交换 4 个报文段，比普通握手增加一个报文段；每一端既是客户又是服务器
      - 同时关闭，并没有太大的区别
  
    - 重置报文段的作用
  
      - 一般来说在 TCP 报文头部设置RST字段，当连接不正确时，将会回应 RST 报文段，这将会导致 TCP 连接快速卸载。RST 字段有两大特性:
      - 任何排队的数据都会被丢弃
      - 只有发送RST 字段就说明 TCP 不是正常关闭
  
    - TCP 保活
  
      - 不影响数据流内容的情况下探测对方的方式

      - 数据线可以断开再连接，只要连接两端的主机没有重启，就可以认为是一致连接的状态
      - 两端需要了解 什么时候终止TCP连接进程 或者 两者没有数据交换但是任然需要保持最小数据流，TCP 保活机制就是应对这两种情况设计的；TCP 保活机制是现实世界需要的；TCP 保活机制通过 Timer 机制（定时器）实现
      - TCP 保活机制的问题
        - 出现短暂的网络错误会导致网络连接断开
        - 保活机制会占用不必要的带宽
        - 长时间的频繁交互式应用程序不需要保活，例如 SSH 连接或者远程桌面连接
  
  - TCP 传输与拥塞

    - TCP的传输控制和拥塞控制都采用了窗口的算法思想，其中传输控制叫做滑动窗口，拥塞控制叫做拥塞窗口
    - 滑动窗口协议：，属于TCP 协议的一种应用，用于网络数据传输时的流量控制，以避免拥塞的发生。该协议允许发送方在停止并等待确认前发送多个数据分组；由于发送方不必每发一个分组就停下来等待确认。因此该协议可以加速数据的传输，提高网络吞吐量
    - TCP 设计了利用 Timer（定时器）机制的持续计数器来间歇性的查询接收端，观察接受窗口是否增长，这个过程叫做窗口探测
    - 窗口探测采用 TCP 传输，可以避免传输过程中的死锁；由于 TCP 会不断的发送窗口探测，可能不会重传操作，导致资源损耗
    - 糊涂窗口综合征：频繁发送的较小数据，导致资源进一步耗尽且影响传输效率，因此
      - 对于接收端来说，不应该通告较小的窗口值
      - 对于发送端来说，不应该发送较小的报文段
    - 设备速度不一样是拥塞产生的原因之一，也可能是因为路由器无法高速处理到达的流量而被迫丢弃数据，这种现象叫做拥塞
    - 针对丢包，TCP 采取的手段是超时重传和快速重传
    - 拥塞窗口是为了防止过多的数据注入到网络中。数据过多会导致网络中的路由器或链路过载
    - 拥塞控制是全局性的过程；结果集趋近于想要的数据，这就叫做收敛的过程
    - 在 TCP 的设计中，通过在发送端维护一个窗口变量确保发送端的发送速率不会超过网络链路的吞吐率和接收端的处理速率；TCP 使用了慢启动和拥塞避免两大算法
  
  - 为什么需要 3 个 ACK （要背）
  
  - TCP Reno 拥塞控制算法
  
    - 线性增加、乘性减少
    - 慢启动
      - 是传输控制协议（TCP）使用的一种阻塞控制机制。慢启动也叫做指数增长期。慢启动是指每次TCP接收窗口收到确认时都会增长。增加的大小就是已确认段的数目。
    - 对超时事件的反应：TCP 对收到3个冗余ACK和超时事件的反应是不一样的
  
  - 总结 TCP 可靠数据传输的原理（要背）
  
    TCP是在端到端不可靠的网络层IP上实现的可靠传输



网络层

- RIP 协议

​		以跳数作为度量，超过15条认为不可达，最多支持等价路径负载均衡，默认是4条。

- OSPF

  - OSPF 多区域中路由器可分为以下4种类型:

    - 内部路由器

    - 主干路由器

    - 区域边界路由器(ABR)

    - 自治域系统边界路由器(ASBR)

  - OSPF 的区域类型：

    - 标准区域
    - 主干区域
    - 末梢区域/末节区域
    - 完全末梢区域
    - 非纯末梢区域(NSSA)
    - 完非纯全末梢区域

  - OSPF 的三张表

    - 邻居表
    - 拓扑表
    - 路由表

  - BGP（外网路由协议）

    每个数据中心为一个自制系统AS，AS有以下分类:

    -  Stub AS:对外只有
    - Multihomed AS:口
    - Transit AS:有多个
    - BGP分为 eBGP 和 iBGP ：自治系统间，边界路由器之间使用 eBGP 广播路由。边界路由器通过 iBGP 将学习到的路由信息导入到内部网络。BGP 协议的其中一个缺点是收敛过程慢。
    - 路由分静态路由和动



数据链路层

适配器是一个半自治的单元

- 网卡就是一个适配器



生成树协议

​	Switch支持STP生成树协议，并给予CAM表进行数据包转发，因此可以构建出物理有环，逻辑无环的逻辑拓扑避免广播风暴。

- CAM表：是交换机在二层转发数据要查找的表，表中有MAC地址，对应的端口号，端口所属的VLAN
- 开机以后直接广播一条数据，这样就能发现环路并将其标记，使其数据线不传输信号



Socket 套接字

- 是一个对 TCP / IP协议进行封装的编程调用接口（API）
- 是在应用层和传输层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用以实现进程在网络中通信。
- Socket是支持TCP/IP协议的网络通信的基本操作单元，是对网络通信过程中端点的抽象表示



- select、poll、epoll的应用场景是什么?
  - 为文件而应运而生的
  - select应用场景：select 的 timeout 参数精度为微秒，而poll和epoll为毫秒，因此 select更加适用于实时性要求比较高的场景，比如核反应堆的控制，医疗中的心跳检测。selct可移植性更好，几乎被所有主流平台所支持；window 使用select ；实时的；轮询，一个一个的查询
  - poll 应用场景：poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用poll而不是select。
  - epoll 应用场景：只能运行再Linux上，因为需要吞吐；就类似直接从客户端发送消息给服务端，而不是服务端主动要
- Unix 的五种 IO 模型
  - 阻塞式IO
  - 非阻塞式IO
  - 信号驱动式IO
  - IO多路复用
  - 异步AIO



流媒体

- 音视频直播
  - 泛娱乐化直播
    - 当直播端直播时向信令服务器发送请求，信令服务器向请求端返回推流地址，直播端开始向CDN 推送数据，用户请求信令服务器得到直播地址，然后再拉取CDN 数据流
  - 实时互动直播
    - 和泛娱乐化直播类似，但是要求的时延不一样

P2P 和 P2SP

- P2SP：P2SP的“S”是指服务器；P2SP有效地通过多媒体检索数据库这个桥梁把原本孤立的服务器资源和P2P资源整合到了一起。 是迅雷的一种非标准格式
- 去中心化网络（DHT）
  - 加入这个网络的每一个节点都需要承担存储任务
- 为什么P2P 下载会到99%就卡住
  - 会把压力转移到client，即自己的电脑 



数据中心

- 概述

  - 机架(Rack)
  - 边界路由器(Border Router)：数据中心的入口和出口也是路由器；在数据中心的边界
  - 自治区域(AS)：是路由器，需要跑路由协议OSPF 协议；数据中心往往就是路由协议中的自治区域(AS)
  - 多线BGP：是许多个运营商都连接上，下载时走三家的流量同时下载
  - TOR (Top Of Rack)交换机：放在机架顶端的
  - 接入层交换机：TOR交换机所在的层经常称作接入层
  - 汇聚层交换机：将很多的机架连接在一起的交换机叫汇聚层交换机
  - 网卡绑定(Bond)：
  - LACP (Link Aggregation Control Protocol)
  - 主备交换机
  - 堆叠交换机
  - Pod、可用区：在这个集群里面，服务器之间通过二层互通，这个区域常称为一个Pod(Point Of Delivery)，时候也称为一个可用区(Available zone)；部署服务时要部署在不同的服务区中，当即是当整个可用区的
  - 集群：聚层将大量的计算节点相互连接在一起，形成一个集群
  - 核心交换机：连接多个可用区的交换机称为核心交换机

- 普通数据中心架构图（要看）

  - 全互联模式：核心交换机吞吐量更大，高可用要求更高，肯定需要堆叠，但是往往仅仅堆叠，不足以满足吞吐量，因而还是需要部署多组核心交换机；核心和汇聚交换机之间为了高可用，也是全互连模式的，即核心和汇聚交换机相互连接
  - 对于全互联模式出现环路怎么办?
  - 大二层TRILL多链接透明互联协议
  - ETRILL多链接透明互联协议
  - Egress RBridge和Ingress RBridge封装在 TRILL Header 中

- 典型的三层网络结构（要看）

  - 对于大二层的广播包，也需要通过分发树的技术来实现。我们知道STP是将一个有环的图，通过去掉边形成一操树。而分发树的是一个有环的图形成多棵树。不同的批有不同的VLAN，有的广播包从VLAN A广福。有的从VLAN B广播，实现负载均衡和高可用
  - 在核心交换上面，往往会挂一些安全设备，例如入侵检测、DDoS防护等等。这是整个数据中心的屏障，防止来自外来的攻击
    - SLB ：负责均衡

- 叶脊网络（要看）

  扁平结构，应当数据中心的东西流量
  
  - 东西流量：服务器与服务器之间的流量
  - 南北流量：客户端与服务器之间的流量
  - 因为东西流量需要拷贝文件，所有带宽一定比南北流量大
  - 叶子交换机：直接连接物理服务器；L2/L3网络的分界点在叶子交换机上，叶子交换机之上是三层网络；三层具备路由能力，二层具备交换能力
  - 脊交换机：相当于核心交换机
  
- 防火墙

  - 四表：filter、nat、mangle、raw、默认表是filter（没有指定表的时候就是filter表）

    filter：一般的过滤功能
    nat：用于nat功能（端口映射，地址映射等）
    mangle：用于对特定数据包的修改
    raw：有限级最高，设置raw时一般是为了不再让 iptables 做数据包的链接跟踪处理，提高性能

  - 五链：PREROUTING、INPUT、FORWARD、OUTPUT、POSTROUTING

    PREROUTING：数据包进入路由表之前
    INPUT：通过路由表后目的地为本机
    FORWARD：通过路由表后，目的地不为本机
    OUTPUT：由本机产生，向外转发
    POSTROUTIONG：发送到网卡接口之前

  - 控制网络的 QoS 的方式

    - 无类别排队规则
      - pfifo_fast：三个先进先出队列，从 0 到 3 依次发送
      - 随机公平队列：同样分为先进先出（FIFO）队列，通过 hash 值区别
      - 令牌桶规则(TBF，Token Bucket Filte）：令牌生成的速度是固定的
    - 有类别排队规则
      - 分层令牌桶规则（HTB，Hierarchical Token Bucket）：将令牌桶分层

- GRE 和 VXLAN

  - GRE：是一种点对点隧道，如果有三个网络，就需要在每两个网络之间建立一个隧道；将IP数据包封装到GRE数据包中，外边加上IP头；不支持组播；很多防火墙和三层网络设备无法解析 GRE，因此它们无法对 GRE 封装包做合适地过滤和负载均衡

    - 组播：将报文从一个源发出，被转发到一组特定的接收者

  - VXLAN：只是在二层协议外边封装了一个 VXLAN 头，VXLAN 是24位的

  - 两者的区别

    VXLAN 不是点对点的，而是支持通过组播的来定位目标机器的，而非一定是这一端发出，另一端接收

- 容器网络基础（重点）

  - Network Namespace

    - Linux的 namespace 给里面的进程造成了两个错觉：

      (1）它是系统里唯一的进程

      (2）它独享系统的所有资源

    - networknamespace的增删改查功能已经集成到Linux的ip工具的 netns 子命令中，因此大大降低了初学者的体验门槛

    - 用户可以臆意将虚糊网络设备分配到自定义network namespace里，而连接真实硬件的物理设备则只能放在系统的根network namespace中，并且，任何一个网络设备最多只能存在于一个network namespace中

  - 虚拟网卡对

    - 像 Linux 的双向管道；经典容器组网模型就是veth pair+bridge的模式
      - 把veth pair想象成一个连接了两个网卡的设备，一端连接namespace，另外一端连接bridge

  - Linux Bridge

    - Linux Bridge 不能跨机连接网络设备，因为它是虚拟的二层设备；出口取决与 MAC 地址就表明了是二层设备，虚拟的低端交换机
    - 在虚拟机场景下，虚拟器一般会和主机在同一个网段;而在容器场景下，容器和物理网络不在同一个网段内，因为有namespace隔离了

  - TUN/TAP 设备

    - 从Linux文件系统的角度看，它是用户可以用文件句柄操作的字符设备;从网络虚拟化角度看，它是虚拟网卡，一端连着网络协议栈，另一端连着用户态程序

    - tun表示虚拟的是点对点设备，tap表示虚拟的是以太网设备，这两种设备针对网络包实施不同的封装

      - 虚拟网卡是以太网设备

    - tap 设备与 tun 设备的工作原理完全相同，区别在于:

      tun设备的/dev/tunX文件收发的是IP包，因此只能工作在L3，无法与物理网卡做桥接，但可以通过三层交换（例如ip_forward)与物理网卡连通。

      tap设备的/dev/tapX文件收发的是链路层数据包，可以与物理网卡做桥接

  - Iptables

    - iptables 的底层实现是netfilter（过滤器框架），netfilter是Linux内核2.4版引入的一个子系统

    - iptables的5张表：

      filter表：用于控制到达某条链上的数据包是继续放行、直接丢弃(drop）或拒绝（reject) ;

      nat表：用于修改数据包的源和目的地址;

      mangle表：用于修改数据包的IP头信息;

      raw表： iptables是有状态的，即iptables对数据包有连接追踪(connectiontracking)机制，而raw是用来去除这种追踪机制的;

      security表∶最不常用的表（(通常，我们说iptables只有4张表,security表是新加入的特性)，用于在数据包上应用SELinux

      - 这5张表的优先级从高到低是:raw、mangle、nat、filter、security

  - IPIP

    tun经常被用来做隧道通信(tunnel)。命令ip tunnel可以实现ipip的管理

    - Linux原生支持下列5种L3隧道：

      ipip：

      GRE：

      sit：

      ISATAP：

      VTI：

  - VXLAN

    - 通过三层的网络搭建虚拟的二层网络；三层网络是有路由器的，这就会发送头部的IP地址会封装和解封装，MAC 地址会发生变化
    - 在底层物理网络(underlay)之上使用隧道技术
    - VXLAN这类隧道网络的一个特点是对原有的网络架构影响小，可以在原有的网络上再构建一个新的网络
    - VXLAN是一个一对多的网络，并不仅是一对一的隧道协议
    - VTEP：VXLAN网络的边缘设备，用来进行VXLAN报文的处理(封包和解包)
    - VNI：VNI是每个VXLAN的标识，是个24位整数，因此最大值是2^24=16777216

  - MACVLAN

    - Macvlan允许用户在主机的一个网络接口上配置多个虚拟的网络接口，即给网卡配置多个虚拟地址

    - keepalived 使用虚拟MAC 地址

    - 使用Macvan的虚拟机或者容器网络与主机在同一个网段，即同一个广播域中

      - 广播域和冲突域的区别

        概念不同：广播域指的是所有接收广播信息的节点，冲突域指的是同一物理段中的节点。 

        协议不同：广播域采用数据链路层协议，冲突域采用物理层协议

        网段不同：广播域可以跨网段，冲突域发生在同一个网段

    - Macvlan支持5种模式，分别是bridge、VEPA、Private、Passthru和Source模式

    - 一般情况下，Macvlan设备的MAC地址是Linux系统自动分配的，用户也可以自定义

    - 当同时满足以下两个条件时，可以实现Macvlan网络的跨主机通信︰

      通信两端的主机在网卡配置混杂模式

      - 混杂模式：指网卡能接受所有通过它的数据流，无论是什么模式、什么地址的

      两台主机上的Macvlan子网IP段没有重叠 

  - IPVLAN

    lPvlan所有的虚拟接口都有相同的MAC地址，而IP地址却各不相同

  - CNM (集中式网络管理)

    容器的网络方案可以分为三大部分∶单机的容器间通信；跨主机的容器间通信；容器与主机间通信

    - 目前有两种主流的网络接口方案，即Docker主导的 CNM 和Kubernetes社区主推的 CNI，其中CNM相对CNI较早提出，CNI 是主流

    - docker的网络类型

      bridge：网桥网络 

      host：主机网络

      none：禁用容器网络

      container：容器网络，Kubernetes的Pod网络采用的就是Docker的container模式网络

    - 而CNM中主要有沙盒(sandbox)、端点(endpoint)、网络(network)这3种组件

    Libnetwork 提供的驱动类型：

    ​	bridge驱动

    ​	host驱动

    ​	overlay驱动

    ​	remote驱动

    ​	null驱动

    - 容器网络与虚拟机网络的对比：

      （略）

    - flannel、Weave、Calico 三个经常用的网络插件

  - CNI 

    - 用于连接容器管理系统和网络插件
  
    - CNI的优势是兼容其他容器技术（例如rkt)及上层编排系统
    - 集群内访问Pod，会经过Service，Service 提供了四层网络负载均衡，不具备七层

  - K8S 的网络插件
  
    - Flannel仅仅作为单租户的容器互联方案是很不错的，但需要额外的组件实现更高级的功能，例如网络隔离、服务发现和负载均衡等，适合小型公司
    - Calico可以创建并管理一个3层平面网络，为每个工作负载分配一个完全可路由的IP地址
    - Calico的核心设计思想就是Router
    - Calico的缺点是网络规模会受到BGP网络规模的限制
      - BGP ：边关网络协议，用来连接Internet上的独立系统的路由选择协议，采用BGP方案来实现双线路互联或多线路互联的机房，称为BGP机房。BGP服务器我们一般称为多线
    - Calico的应用场景主要在IDC内部，calico官方推荐将其部署在大二层网络上，这样所有路由器之间是互通的
      - 所谓大二层就是没有任何三层的网关，所有的机器、宿主机、物理机在二层是可达的。大二层主要的问题是弹性伸缩的问题

  - SDN、OVS

    - 特点：

      控制与转发分离：转发的数据量特别大，控制信号可能发不下去，隔离的思想

      控制平面与转发平面之间的开放接口

      逻辑上的集中控制

  - 网络安全
  
    - 跨站脚本攻击（XSS）
      - 可以将代码注入到用户浏览的网页上，这种代码包括HTML和JavaScript
    - 跨站请求伪造（CSRF）
      - 是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并执行一些操作〈如发邮件，发消息，甚至财产操作如转账和购买商品)
    - XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户浏览器的信任。



